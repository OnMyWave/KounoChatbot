{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wmkim\\miniconda3\\envs\\gpt3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.12.1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "  pad_token_id=tokenizer.eos_token_id,\n",
    "  torch_dtype='auto', low_cpu_mem_usage=True\n",
    ").to(device='cuda', non_blocking=True)\n",
    "_ = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kcbert': 'beomi@github 님이 만드신 KcBERT 학습데이터',\n",
       " 'korean_chatbot_data': 'songys@github 님이 만드신 챗봇 문답 데이터',\n",
       " 'korean_hate_speech': '{inmoonlight,warnikchow,beomi}@github 님이 만드신 혐오댓글데이터',\n",
       " 'korean_parallel_koen_news': 'jungyeul@github 님이 만드신 병렬 말뭉치',\n",
       " 'korean_petitions': 'lovit@github 님이 만드신 2017.08 ~ 2019.03 청와대 청원데이터',\n",
       " 'kornli': 'KakaoBrain 에서 제공하는 Natural Language Inference (NLI) 데이터',\n",
       " 'korsts': 'KakaoBrain 에서 제공하는 Semantic Textual Similarity (STS) 데이터',\n",
       " 'kowikitext': 'lovit@github 님이 만드신 wikitext 형식의 한국어 위키피디아 데이터',\n",
       " 'namuwikitext': 'lovit@github 님이 만드신 wikitext 형식의 나무위키 데이터',\n",
       " 'naver_changwon_ner': '네이버 + 창원대 NER shared task data',\n",
       " 'nsmc': 'e9t@github 님이 만드신 Naver sentiment movie corpus v1.0',\n",
       " 'question_pair': 'songys@github 님이 만드신 질문쌍(Paired Question v.2)',\n",
       " 'modu_news': '국립국어원에서 만든 모두의 말뭉치: 뉴스 말뭉치',\n",
       " 'modu_messenger': '국립국어원에서 만든 모두의 말뭉치: 메신저 말뭉치',\n",
       " 'modu_mp': '국립국어원에서 만든 모두의 말뭉치: 형태 분석 말뭉치',\n",
       " 'modu_ne': '국립국어원에서 만든 모두의 말뭉치: 개체명 분석 말뭉치',\n",
       " 'modu_spoken': '국립국어원에서 만든 모두의 말뭉치: 구어 말뭉치',\n",
       " 'modu_web': '국립국어원에서 만든 모두의 말뭉치: 웹 말뭉치',\n",
       " 'modu_written': '국립국어원에서 만든 모두의 말뭉치: 문어 말뭉치',\n",
       " 'open_subtitles': 'Open parallel corpus (OPUS) 에서 제공하는 영화 자막 번역 병렬 말뭉치',\n",
       " 'aihub_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어 + 대화 + 뉴스 + 한국문화 + 조례 + 지자체웹사이트)',\n",
       " 'aihub_spoken_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어)',\n",
       " 'aihub_conversation_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (대화)',\n",
       " 'aihub_news_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (뉴스)',\n",
       " 'aihub_korean_culture_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (한국문화)',\n",
       " 'aihub_decree_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (조례)',\n",
       " 'aihub_government_website_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (지자체웹사이트)'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.corpus_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "아두이노 관련된 질문이 있어요 \n",
      "아두이노 우노로 어두워지면 led켜지게 하려는데 어떻게 해야할까요\n",
      "아두이노 우노로 LED 켤때마다 소리 나게 만드는데 어떻게 해야될까요\n",
      "아두이노 관련된 질문이 있어요 \n",
      "아두이노 우노로 어두워지면 led켜지게 하려는데 어떻게 해야될까요\n",
      "아두이노 우노로 LED 켤때마다 소리 나게 만드는데 어떻게 해야될까요\n",
      "(참고자료)\n",
      "아두이노 우노의 기본적인 개념\n",
      "아두이노 우노에서 사용하는 센서와 부품 그리고 프로그래밍 하는 방법\n",
      "아두이노 우노를 활용한 창의로봇[EOS]\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "아두이노 관련된 질문이 있어요 \n",
    "아두이노 우노로 어두워지면 led켜지게 하려는데 어떻게 해야할까요\n",
    "'''\n",
    "with torch.no_grad():\n",
    "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
    "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=512)\n",
    "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
    "  \n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c73fcc5bd538744f6925f2bb7d559cd1bbb2644bdd042e10b1c37f95ad282db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
